dataset,version,metric,mode,ngpt_converted_v2_hf
commonsense_qa,734a22,accuracy,gen,8.93
chid-dev,211ee7,accuracy,gen,3.47
chid-test,211ee7,accuracy,gen,3.75
openai_humaneval,8e312c,humaneval_pass@1,gen,0.00
bbh-temporal_sequences,e43931,score,gen,12.80
bbh-disambiguation_qa,d52c61,score,gen,26.80
bbh-date_understanding,a8000b,score,gen,17.60
bbh-tracking_shuffled_objects_three_objects,7964c0,score,gen,32.80
bbh-penguins_in_a_table,fceb27,score,gen,15.75
bbh-geometric_shapes,503c8f,score,gen,0.00
bbh-snarks,42d6ca,score,gen,52.81
bbh-ruin_names,408de8,score,gen,20.80
bbh-tracking_shuffled_objects_seven_objects,7964c0,score,gen,11.20
bbh-tracking_shuffled_objects_five_objects,7964c0,score,gen,21.20
bbh-logical_deduction_three_objects,45ebc5,score,gen,31.60
bbh-hyperbaton,5e5016,score,gen,52.80
bbh-logical_deduction_five_objects,45ebc5,score,gen,16.00
bbh-logical_deduction_seven_objects,45ebc5,score,gen,10.00
bbh-movie_recommendation,cc2fde,score,gen,25.60
bbh-salient_translation_error_detection,5b5f35,score,gen,0.80
bbh-reasoning_about_colored_objects,1cb761,score,gen,16.80
bbh-multistep_arithmetic_two,30f91e,score,gen,0.00
bbh-navigate,1576d9,score,gen,0.00
bbh-dyck_languages,805bea,score,gen,0.00
bbh-word_sorting,9a3f78,score,gen,0.00
bbh-sports_understanding,d3fa77,score,gen,45.20
bbh-boolean_expressions,612c92,score,gen,23.20
bbh-object_counting,781e5c,score,gen,0.00
bbh-formal_fallacies,eada96,score,gen,12.80
bbh-causal_judgement,89eaa4,score,gen,3.74
bbh-web_of_lies,0c0441,score,gen,3.20
gsm8k,1d7fe4,accuracy,gen,2.43
truthful_qa,5ddc62,bleu_max,gen,0.06
truthful_qa,5ddc62,bleu_diff,gen,-0.02
truthful_qa,5ddc62,bleu_acc,gen,0.15
bbh,-,naive_average,gen,16.80